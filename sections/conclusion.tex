% !TEX root = main.tex

\section{Conclusions and Future Work}

Planned improvements include enhancing support for users who wear glasses through prescription lens calibration techniques, and extending system compatibility to mobile and AR/VR platforms. Additional enhancements involve creating onboarding guides and integrating visual cues to facilitate learning gaze-based input, as well as including individuals with motor impairments in future user studies to better validate accessibility benefits. The system's test recorder is also being developed as a standalone tool to support broader usability testing efforts. Finally, there are plans to explore integration with immersive environments, such as the Apple Vision Pro and Meta Quest, to evaluate usability and responsiveness in mixed-reality contexts.

In summary, EyeNav demonstrates a novel fusion of eye-tracking and NLP to deliver an accessible, hands-free web-interaction paradigm while simultaneously generating executable, Gherkin-based test scripts. By orchestrating these modules, EyeNav provides developers and usability professionals with an intuitive tool for rapid prototyping and automated testing. 